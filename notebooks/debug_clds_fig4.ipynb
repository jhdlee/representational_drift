{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug CLDS Model - Figure 4 Experiment\n",
    "This notebook debugs CLDS training for the figure 4 calcium imaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dynamax.linear_gaussian_ssm.models import LinearGaussianConjugateSSM, ConditionallyLinearGaussianSSM\n",
    "from dynamax.utils.utils import Tm_basis, rbf_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "state_dim = 5\n",
    "L = 7  # number of basis functions\n",
    "kappa = 0.2  # lengthscale for RBF, smoothness for Fourier\n",
    "sigma = 1.0  # amplitude\n",
    "basis_type = 'rbf'  # 'rbf' or 'fourier'\n",
    "has_dynamics_bias = True\n",
    "\n",
    "# Data parameters\n",
    "data_path = '/home/groups/swl1/hdlee/nast/neurips_2025'\n",
    "block_size = 4\n",
    "standardize = True\n",
    "\n",
    "# Training parameters\n",
    "num_iters = 50  # reduced for debugging\n",
    "seed = 2626\n",
    "model_seed = 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emissions and conditions (calcium imaging data)\n",
    "emissions_path = os.path.join(data_path, 'data_calcium_v5.npy')\n",
    "conditions_path = os.path.join(data_path, 'conditions_calcium_v5.npy')\n",
    "\n",
    "emissions = jnp.load(emissions_path).astype(jnp.float64)\n",
    "conditions = jnp.load(conditions_path).astype(int)\n",
    "\n",
    "print(f\"Emissions shape: {emissions.shape}\")\n",
    "print(f\"Conditions shape: {conditions.shape}\")\n",
    "print(f\"Unique conditions: {jnp.unique(conditions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_non_consecutive(key, a, b, k):\n",
    "    \"\"\"Select k non-consecutive integers from [a, b]\"\"\"\n",
    "    n = b - a + 1\n",
    "    if k > (n + 1) // 2:\n",
    "        raise ValueError(\"Not enough non-consecutive numbers to select.\")\n",
    "    \n",
    "    available = jnp.arange(a, b + 1)\n",
    "    selected = []\n",
    "\n",
    "    for _ in range(k):\n",
    "        key, subkey = jr.split(key)\n",
    "        idx = jr.randint(subkey, (), 0, len(available))\n",
    "        choice = available[idx]\n",
    "        selected.append(choice)\n",
    "\n",
    "        # Remove choice and its neighbors\n",
    "        mask = (available != choice) & (available != choice - 1) & (available != choice + 1)\n",
    "        available = available[mask]\n",
    "\n",
    "    return jnp.sort(jnp.array(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "num_conditions = len(np.unique(conditions))\n",
    "num_blocks = len(emissions) // block_size\n",
    "num_trials = num_blocks * block_size\n",
    "emissions = emissions[:num_trials]\n",
    "conditions = conditions[:num_trials]\n",
    "\n",
    "# Create train/test split at block level (non-consecutive test blocks)\n",
    "block_masks = jnp.ones(num_blocks, dtype=bool)\n",
    "num_test_blocks = num_blocks // 4\n",
    "key = jr.PRNGKey(seed)\n",
    "test_idx = select_non_consecutive(key, 6, num_blocks-6, num_test_blocks)\n",
    "block_masks = block_masks.at[test_idx].set(False)\n",
    "\n",
    "# Temporal indices (block-level)\n",
    "block_id_nums = jnp.repeat(jnp.arange(num_blocks, dtype=float), block_size)\n",
    "block_id_nums = block_id_nums / (num_blocks - 1)  # normalize to [0, 1]\n",
    "\n",
    "trial_masks = jnp.repeat(block_masks, block_size)\n",
    "train_conditions = conditions[trial_masks]\n",
    "test_conditions = conditions[~trial_masks]\n",
    "\n",
    "# Standardize\n",
    "if standardize:\n",
    "    train_obs_ = emissions[trial_masks]\n",
    "    train_obs_mean = jnp.mean(train_obs_, axis=(0, 1), keepdims=True)\n",
    "    train_obs_std = jnp.std(train_obs_, axis=(0, 1), keepdims=True)\n",
    "    train_obs = (emissions - train_obs_mean) / train_obs_std\n",
    "else:\n",
    "    train_obs = emissions\n",
    "\n",
    "_, sequence_length, emission_dim = train_obs.shape\n",
    "test_obs = train_obs[~trial_masks]\n",
    "\n",
    "print(f\"Num blocks: {num_blocks}, Block size: {block_size}\")\n",
    "print(f\"Num train trials: {trial_masks.sum()}, Num test trials: {(~trial_masks).sum()}\")\n",
    "print(f\"Emission dim: {emission_dim}, Sequence length: {sequence_length}\")\n",
    "print(f\"Unique block_id_nums (train): {len(jnp.unique(block_id_nums[trial_masks]))}\")\n",
    "print(f\"Test block indices: {test_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basis functions\n",
    "if basis_type == 'rbf':\n",
    "    basis_funcs = rbf_basis(L, M_conditions=1, sigma=sigma, kappa=kappa)\n",
    "else:\n",
    "    period = 1.0 + 6.0 * kappa\n",
    "    basis_funcs = Tm_basis(L, M_conditions=1, sigma=sigma, kappa=kappa, period=period)\n",
    "\n",
    "print(f\"Number of basis functions: {len(basis_funcs)}\")\n",
    "\n",
    "# Initialize model\n",
    "model = ConditionallyLinearGaussianSSM(\n",
    "    state_dim=state_dim,\n",
    "    emission_dim=emission_dim,\n",
    "    num_conditions=num_conditions,\n",
    "    has_dynamics_bias=has_dynamics_bias,\n",
    "    torus_basis_funcs=basis_funcs,\n",
    "    num_trials=len(train_obs[trial_masks]),\n",
    ")\n",
    "\n",
    "key = jr.PRNGKey(model_seed)\n",
    "params, props = model.initialize(key=key)\n",
    "\n",
    "print(f\"\\nInitial emission weights shape: {params.emissions.weights.shape}\")\n",
    "print(f\"  Expected: (L={len(basis_funcs)}, emission_dim={emission_dim}, state_dim={state_dim})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: Check Basis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate basis functions at different time points\n",
    "print(\"Basis function values at different time points:\")\n",
    "t_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "for t in t_values:\n",
    "    phi = model.wpgs_C.evaluate_basis(t)\n",
    "    print(f\"  t={t:.2f}: {phi[:5]}... (sum={phi.sum():.3f})\")\n",
    "\n",
    "# Plot basis functions\n",
    "t_range = jnp.linspace(0, 1, 100)\n",
    "phi_values = jnp.array([model.wpgs_C.evaluate_basis(t) for t in t_range])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(min(len(basis_funcs), 7)):\n",
    "    plt.plot(t_range, phi_values[:, i], label=f'Basis {i}')\n",
    "plt.xlabel('Time (normalized)')\n",
    "plt.ylabel('Basis function value')\n",
    "plt.title(f'{basis_type.upper()} Basis Functions (L={L}, kappa={kappa}, sigma={sigma})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CLDS\n",
    "best_params, train_lps = model.fit_em(\n",
    "    params=params,\n",
    "    props=props,\n",
    "    emissions=train_obs[trial_masks],\n",
    "    conditions=train_conditions,\n",
    "    block_id_nums=block_id_nums[trial_masks],\n",
    "    num_iters=num_iters,\n",
    "    use_wandb=False,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal train log-likelihood: {train_lps[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_lps)\n",
    "plt.xlabel('EM Iteration')\n",
    "plt.ylabel('Log-likelihood')\n",
    "plt.title('CLDS Training Curve')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: Check Learned Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check emission weights\n",
    "W_C = best_params.emissions.weights\n",
    "print(f\"Emission weights shape: {W_C.shape}\")\n",
    "print(f\"Mean absolute weight per basis function:\")\n",
    "mean_abs_weights = jnp.abs(W_C).mean(axis=(1, 2))\n",
    "for i, w in enumerate(mean_abs_weights):\n",
    "    print(f\"  Basis {i}: {w:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check emission matrix variation over time\n",
    "print(\"\\nEmission matrix norm at different times:\")\n",
    "C_matrices = []\n",
    "for t in t_values:\n",
    "    C_t = model.wpgs_C(best_params.emissions.weights, t)\n",
    "    C_matrices.append(C_t)\n",
    "    print(f\"  t={t:.2f}: ||C|| = {jnp.linalg.norm(C_t):.4f}\")\n",
    "\n",
    "# Relative change from start to end\n",
    "C_0 = C_matrices[0]\n",
    "C_1 = C_matrices[-1]\n",
    "rel_change = jnp.linalg.norm(C_1 - C_0) / jnp.linalg.norm(C_0)\n",
    "print(f\"\\n||C(1) - C(0)|| / ||C(0)|| = {rel_change:.4f}\")\n",
    "print(f\"  (This should be > 0.1 for meaningful time variation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot emission matrix norm over time\n",
    "C_norms = [jnp.linalg.norm(model.wpgs_C(best_params.emissions.weights, t)) for t in t_range]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(t_range, C_norms)\n",
    "plt.xlabel('Time (normalized)')\n",
    "plt.ylabel('||C(t)||')\n",
    "plt.title('Emission Matrix Norm Over Time')\n",
    "plt.grid(True)\n",
    "\n",
    "# Mark test block positions\n",
    "test_block_times = test_idx / (num_blocks - 1)\n",
    "for t in test_block_times:\n",
    "    plt.axvline(x=t, color='r', linestyle='--', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with LDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDS for comparison\n",
    "lds_model = LinearGaussianConjugateSSM(\n",
    "    state_dim=state_dim,\n",
    "    emission_dim=emission_dim,\n",
    "    num_conditions=num_conditions,\n",
    "    has_dynamics_bias=has_dynamics_bias,\n",
    ")\n",
    "\n",
    "key = jr.PRNGKey(model_seed)\n",
    "lds_params, lds_props = lds_model.initialize(key=key)\n",
    "\n",
    "best_lds_params, lds_train_lps = lds_model.fit_em(\n",
    "    params=lds_params,\n",
    "    props=lds_props,\n",
    "    emissions=train_obs[trial_masks],\n",
    "    conditions=train_conditions,\n",
    "    num_iters=num_iters,\n",
    "    use_wandb=False,\n",
    ")\n",
    "\n",
    "print(f\"LDS final train log-likelihood: {lds_train_lps[-1]:.2f}\")\n",
    "print(f\"CLDS final train log-likelihood: {train_lps[-1]:.2f}\")\n",
    "print(f\"Difference (CLDS - LDS): {train_lps[-1] - lds_train_lps[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare test log-likelihoods\n",
    "test_block_ids = block_id_nums[~trial_masks]\n",
    "\n",
    "clds_test_ll = model.batch_marginal_log_prob(\n",
    "    best_params, test_obs, conditions=test_conditions, trial_ids=test_block_ids\n",
    ")\n",
    "\n",
    "lds_test_ll = lds_model.batch_marginal_log_prob(\n",
    "    best_lds_params, test_obs, conditions=test_conditions\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Log-Likelihoods:\")\n",
    "print(f\"  LDS:  {lds_test_ll:.2f}\")\n",
    "print(f\"  CLDS: {clds_test_ll:.2f}\")\n",
    "print(f\"  Difference (CLDS - LDS): {clds_test_ll - lds_test_ll:.2f}\")\n",
    "\n",
    "if clds_test_ll < lds_test_ll:\n",
    "    print(f\"\\n  WARNING: CLDS test LL < LDS test LL (overfitting!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Training curves\n",
    "axes[0].plot(train_lps, label='CLDS')\n",
    "axes[0].plot(lds_train_lps, label='LDS')\n",
    "axes[0].set_xlabel('EM Iteration')\n",
    "axes[0].set_ylabel('Log-likelihood')\n",
    "axes[0].set_title('Training Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Test LL comparison\n",
    "axes[1].bar(['LDS', 'CLDS'], [lds_test_ll, clds_test_ll])\n",
    "axes[1].set_ylabel('Test Log-likelihood')\n",
    "axes[1].set_title('Test Performance')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: Overfitting Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check per-test-block log-likelihoods\n",
    "print(\"Per-test-block log-likelihoods:\")\n",
    "print(f\"{'Block':<8} {'Time':<8} {'CLDS':<12} {'LDS':<12} {'Diff':<12}\")\n",
    "print(\"-\" * 52)\n",
    "\n",
    "for i, block_idx in enumerate(test_idx):\n",
    "    # Get trials for this block\n",
    "    block_start = i * block_size\n",
    "    block_end = (i + 1) * block_size\n",
    "    block_obs = test_obs[block_start:block_end]\n",
    "    block_conds = test_conditions[block_start:block_end]\n",
    "    block_times = test_block_ids[block_start:block_end]\n",
    "    \n",
    "    # CLDS LL for this block\n",
    "    clds_block_ll = model.batch_marginal_log_prob(\n",
    "        best_params, block_obs, conditions=block_conds, trial_ids=block_times\n",
    "    )\n",
    "    \n",
    "    # LDS LL for this block\n",
    "    lds_block_ll = lds_model.batch_marginal_log_prob(\n",
    "        best_lds_params, block_obs, conditions=block_conds\n",
    "    )\n",
    "    \n",
    "    time_pos = float(block_idx) / (num_blocks - 1)\n",
    "    diff = clds_block_ll - lds_block_ll\n",
    "    print(f\"{block_idx:<8} {time_pos:<8.3f} {clds_block_ll:<12.2f} {lds_block_ll:<12.2f} {diff:<12.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: Regularization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if regularization is too strong/weak\n",
    "print(\"Regularization Analysis:\")\n",
    "print(f\"  L (basis functions): {len(basis_funcs)}\")\n",
    "print(f\"  state_dim: {state_dim}\")\n",
    "print(f\"  L * state_dim = {len(basis_funcs) * state_dim}\")\n",
    "print(f\"  Current regularization coefficient: 1.0\")\n",
    "print(f\"\\nTo reduce overfitting, increase regularization in models.py line 1715:\")\n",
    "print(f\"  ZTZ + 10.0 * jnp.eye(...)  # or 100.0\")\n",
    "print(f\"\\nOr reduce model complexity:\")\n",
    "print(f\"  - Fewer basis functions (smaller L)\")\n",
    "print(f\"  - Larger kappa (smoother variation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Emission Matrix Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how C changes over time\n",
    "n_timepoints = 5\n",
    "fig, axes = plt.subplots(1, n_timepoints, figsize=(15, 3))\n",
    "\n",
    "for i, t in enumerate(jnp.linspace(0, 1, n_timepoints)):\n",
    "    C_t = model.wpgs_C(best_params.emissions.weights, float(t))\n",
    "    im = axes[i].imshow(C_t[:20, :], aspect='auto', cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n",
    "    axes[i].set_title(f't = {t:.2f}')\n",
    "    axes[i].set_xlabel('Latent dim')\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Emission dim (first 20)')\n",
    "\n",
    "plt.colorbar(im, ax=axes, shrink=0.8)\n",
    "plt.suptitle('Emission Matrix C(t) at Different Times')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
