{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug CLDS Model\n",
    "This notebook debugs CLDS training with a single set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dynamax.linear_gaussian_ssm.models import LinearGaussianConjugateSSM, ConditionallyLinearGaussianSSM\n",
    "from dynamax.utils.utils import Tm_basis, rbf_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "state_dim = 10\n",
    "L = 7  # number of basis functions\n",
    "kappa = 0.2  # lengthscale for RBF, smoothness for Fourier\n",
    "sigma = 1.0  # amplitude\n",
    "basis_type = 'rbf'  # 'rbf' or 'fourier'\n",
    "has_dynamics_bias = True\n",
    "\n",
    "# Data parameters\n",
    "data_path = '/oak/stanford/groups/swl1/hdlee/crcns/U201202_01'\n",
    "block_size = 8\n",
    "standardize = True\n",
    "\n",
    "# Training parameters\n",
    "num_iters = 50  # reduced for debugging\n",
    "seed = 10796\n",
    "model_seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_to_n = {'top':0, 'top_left':1, 'left':2, 'bottom_left':3, \n",
    "                  'bottom':4, 'bottom_right':5, 'right':6, 'top_right':7}\n",
    "\n",
    "# Load emissions and conditions\n",
    "emissions_path = os.path.join(data_path, 'emissions_v4.npy')\n",
    "conditions_path = os.path.join(data_path, 'conditions.npy')\n",
    "\n",
    "emissions = jnp.load(emissions_path)\n",
    "conditions = np.load(conditions_path, allow_pickle=True)\n",
    "for c in condition_to_n.keys():\n",
    "    conditions[np.where(conditions==c)] = condition_to_n[c]\n",
    "conditions = jnp.array(conditions.astype(int))\n",
    "\n",
    "print(f\"Emissions shape: {emissions.shape}\")\n",
    "print(f\"Conditions shape: {conditions.shape}\")\n",
    "print(f\"Unique conditions: {jnp.unique(conditions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "num_conditions = len(np.unique(conditions))\n",
    "num_blocks = len(emissions) // block_size\n",
    "num_trials = num_blocks * block_size\n",
    "emissions = emissions[:num_trials]\n",
    "conditions = conditions[:num_trials]\n",
    "\n",
    "# Create train/test split at block level\n",
    "block_masks = jnp.ones(num_blocks, dtype=bool)\n",
    "num_test_blocks = num_blocks // 6\n",
    "key = jr.PRNGKey(seed)\n",
    "test_idx = jr.choice(key, jnp.arange(8, num_blocks-8, dtype=int), shape=(num_test_blocks,), replace=False)\n",
    "block_masks = block_masks.at[test_idx].set(False)\n",
    "\n",
    "# Temporal indices (block-level)\n",
    "block_id_nums = jnp.repeat(jnp.arange(num_blocks, dtype=float), block_size)\n",
    "block_id_nums = block_id_nums / (num_blocks - 1)  # normalize to [0, 1]\n",
    "\n",
    "trial_masks = jnp.repeat(block_masks, block_size)\n",
    "train_conditions = conditions[trial_masks]\n",
    "test_conditions = conditions[~trial_masks]\n",
    "\n",
    "# Standardize\n",
    "if standardize:\n",
    "    train_obs_ = emissions[trial_masks]\n",
    "    train_obs_mean = jnp.mean(train_obs_, axis=(0, 1), keepdims=True)\n",
    "    train_obs_std = jnp.std(train_obs_, axis=(0, 1), keepdims=True)\n",
    "    train_obs = (emissions - train_obs_mean) / train_obs_std\n",
    "else:\n",
    "    train_obs = emissions\n",
    "\n",
    "_, sequence_length, emission_dim = train_obs.shape\n",
    "test_obs = train_obs[~trial_masks]\n",
    "\n",
    "print(f\"Num blocks: {num_blocks}, Block size: {block_size}\")\n",
    "print(f\"Num train trials: {trial_masks.sum()}, Num test trials: {(~trial_masks).sum()}\")\n",
    "print(f\"Emission dim: {emission_dim}, Sequence length: {sequence_length}\")\n",
    "print(f\"Unique block_id_nums (train): {len(jnp.unique(block_id_nums[trial_masks]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basis functions\n",
    "if basis_type == 'rbf':\n",
    "    basis_funcs = rbf_basis(L, M_conditions=1, sigma=sigma, kappa=kappa)\n",
    "else:\n",
    "    period = 1.0 + 6.0 * kappa\n",
    "    basis_funcs = Tm_basis(L, M_conditions=1, sigma=sigma, kappa=kappa, period=period)\n",
    "\n",
    "print(f\"Number of basis functions: {len(basis_funcs)}\")\n",
    "\n",
    "# Initialize model\n",
    "model = ConditionallyLinearGaussianSSM(\n",
    "    state_dim=state_dim,\n",
    "    emission_dim=emission_dim,\n",
    "    num_conditions=num_conditions,\n",
    "    has_dynamics_bias=has_dynamics_bias,\n",
    "    torus_basis_funcs=basis_funcs,\n",
    "    num_trials=len(train_obs[trial_masks]),\n",
    ")\n",
    "\n",
    "key = jr.PRNGKey(model_seed)\n",
    "params, props = model.initialize(key=key)\n",
    "\n",
    "print(f\"\\nInitial emission weights shape: {params.emissions.weights.shape}\")\n",
    "print(f\"  Expected: (L={len(basis_funcs)}, emission_dim={emission_dim}, state_dim={state_dim})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: Check Basis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate basis functions at different time points\n",
    "print(\"Basis function values at different time points:\")\n",
    "t_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "for t in t_values:\n",
    "    phi = model.wpgs_C.evaluate_basis(t)\n",
    "    print(f\"  t={t:.2f}: {phi[:5]}... (sum={phi.sum():.3f})\")\n",
    "\n",
    "# Plot basis functions\n",
    "t_range = jnp.linspace(0, 1, 100)\n",
    "phi_values = jnp.array([model.wpgs_C.evaluate_basis(t) for t in t_range])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(min(len(basis_funcs), 7)):\n",
    "    plt.plot(t_range, phi_values[:, i], label=f'Basis {i}')\n",
    "plt.xlabel('Time (normalized)')\n",
    "plt.ylabel('Basis function value')\n",
    "plt.title(f'{basis_type.upper()} Basis Functions (L={L}, kappa={kappa}, sigma={sigma})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CLDS\n",
    "best_params, train_lps = model.fit_em(\n",
    "    params=params,\n",
    "    props=props,\n",
    "    emissions=train_obs[trial_masks],\n",
    "    conditions=train_conditions,\n",
    "    block_id_nums=block_id_nums[trial_masks],\n",
    "    num_iters=num_iters,\n",
    "    use_wandb=False,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal train log-likelihood: {train_lps[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curve\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_lps)\n",
    "plt.xlabel('EM Iteration')\n",
    "plt.ylabel('Log-likelihood')\n",
    "plt.title('CLDS Training Curve')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: Check Learned Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check emission weights\n",
    "W_C = best_params.emissions.weights\n",
    "print(f\"Emission weights shape: {W_C.shape}\")\n",
    "print(f\"Mean absolute weight per basis function:\")\n",
    "mean_abs_weights = jnp.abs(W_C).mean(axis=(1, 2))\n",
    "for i, w in enumerate(mean_abs_weights):\n",
    "    print(f\"  Basis {i}: {w:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check emission matrix variation over time\n",
    "print(\"\\nEmission matrix norm at different times:\")\n",
    "C_matrices = []\n",
    "for t in t_values:\n",
    "    C_t = model.wpgs_C(best_params.emissions.weights, t)\n",
    "    C_matrices.append(C_t)\n",
    "    print(f\"  t={t:.2f}: ||C|| = {jnp.linalg.norm(C_t):.4f}\")\n",
    "\n",
    "# Relative change from start to end\n",
    "C_0 = C_matrices[0]\n",
    "C_1 = C_matrices[-1]\n",
    "rel_change = jnp.linalg.norm(C_1 - C_0) / jnp.linalg.norm(C_0)\n",
    "print(f\"\\n||C(1) - C(0)|| / ||C(0)|| = {rel_change:.4f}\")\n",
    "print(f\"  (This should be > 0.1 for meaningful time variation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with LDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDS for comparison\n",
    "lds_model = LinearGaussianConjugateSSM(\n",
    "    state_dim=state_dim,\n",
    "    emission_dim=emission_dim,\n",
    "    num_conditions=num_conditions,\n",
    "    has_dynamics_bias=has_dynamics_bias,\n",
    ")\n",
    "\n",
    "key = jr.PRNGKey(model_seed)\n",
    "lds_params, lds_props = lds_model.initialize(key=key)\n",
    "\n",
    "best_lds_params, lds_train_lps = lds_model.fit_em(\n",
    "    params=lds_params,\n",
    "    props=lds_props,\n",
    "    emissions=train_obs[trial_masks],\n",
    "    conditions=train_conditions,\n",
    "    num_iters=num_iters,\n",
    "    use_wandb=False,\n",
    ")\n",
    "\n",
    "print(f\"LDS final train log-likelihood: {lds_train_lps[-1]:.2f}\")\n",
    "print(f\"CLDS final train log-likelihood: {train_lps[-1]:.2f}\")\n",
    "print(f\"Difference (CLDS - LDS): {train_lps[-1] - lds_train_lps[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare test log-likelihoods\n",
    "test_block_ids = block_id_nums[~trial_masks]\n",
    "\n",
    "clds_test_ll = model.batch_marginal_log_prob(\n",
    "    best_params, test_obs, conditions=test_conditions, trial_ids=test_block_ids\n",
    ")\n",
    "\n",
    "lds_test_ll = lds_model.batch_marginal_log_prob(\n",
    "    best_lds_params, test_obs, conditions=test_conditions\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Log-Likelihoods:\")\n",
    "print(f\"  LDS:  {lds_test_ll:.2f}\")\n",
    "print(f\"  CLDS: {clds_test_ll:.2f}\")\n",
    "print(f\"  Difference (CLDS - LDS): {clds_test_ll - lds_test_ll:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_lps, label='CLDS')\n",
    "plt.plot(lds_train_lps, label='LDS')\n",
    "plt.xlabel('EM Iteration')\n",
    "plt.ylabel('Log-likelihood')\n",
    "plt.title('Training Curves: CLDS vs LDS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: Regularization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if regularization is too strong\n",
    "# The M-step uses: ZTZ + I (identity regularization with coefficient 1.0)\n",
    "\n",
    "print(\"Regularization Analysis:\")\n",
    "print(f\"  L * state_dim = {len(basis_funcs)} * {state_dim} = {len(basis_funcs) * state_dim}\")\n",
    "print(f\"  Regularization coefficient: 1.0\")\n",
    "print(f\"  If ZTZ diagonal << 1.0, regularization dominates!\")\n",
    "print(f\"\\nTo reduce regularization, edit models.py line 1715:\")\n",
    "print(f\"  ZTZ + 1e-4 * jnp.eye(...)  # instead of ZTZ + jnp.eye(...)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
